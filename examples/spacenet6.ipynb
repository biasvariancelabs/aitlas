{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Challenge: Spacenet6 - Multi-Sensor All-Weather Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the usage of the winning [solution](https://github.com/SpaceNetChallenge/SpaceNet_SAR_Buildings_Solutions/tree/master/1-zbigniewwojna) of the [Spacenet6 challenge](https://spacenet.ai/sn6-challenge/). \n",
    "\n",
    "The goal there was to automatically extract building footprints with computer vision and artificial intelligence (AI) algorithms using a combination of SAR and electro-optical imagery datasets. \n",
    "\n",
    "For that purpose the organisers have collected over 120 sq km of both high resolution synthetic aperture radar (SAR) data and electro optical (EO) imagery with ~48,000 building footprint labels of Rotterdam, The Netherlands.\n",
    "\n",
    "The winning solution of the challenge was implemented in `aitlas`. This notebook will demonstrate how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitlas.datasets import SpaceNet6Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step we need to download and prepare the data set. The instructions for downloading are available at the main [page](https://spacenet.ai/sn6-challenge/) of the challenge. Basically, you just need an AWS account with an access key and secret access key in your local configuration file. The data set is quite large (40 GB) and it takes a while to download. Once you do that, initialize a `SpaceNet6Dataset` object and call the `prepare` method to create training folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spopov/Downloads/aitlas/venv/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "### Parameters\n",
    "\n",
    "# base directory after unzipping the downloaded files from S3\n",
    "ROOT_DIRECTORY = \"/Users/spopov/train/AOI_11_Rotterdam\"\n",
    "\n",
    "# directory for storing the ground-truth segmentation masks\n",
    "SEGMENTATION_DIRECTORY = \"/Users/spopov/results/segmentation_masks\"\n",
    "\n",
    "# directory for storing information about the training / validation folds\n",
    "FOLDS_DIR = \"/Users/spopov/results/folds\"\n",
    "\n",
    "# orientation file indicating the directions from which each SAR image is captured (0 North, 1 South).\n",
    "ORIENTS = \"/Users/spopov/train/AOI_11_Rotterdam/SummaryData/SAR_orientations.txt\"\n",
    "\n",
    "# CSV of building footprint locations in pixel coordinates\n",
    "ORIENTS_OUTPUT = \"/Users/spopov/train/AOI_11_Rotterdam/SummaryData/SAR_orientations.csv\"\n",
    "\n",
    "# directory for storing the predicted masks\n",
    "PRED_FOLDER = \"/Users/spopov/results/pred{}\"\n",
    "\n",
    "# path to the CSV file containing the fold splits\n",
    "FOLDS_PATH = \"/Users/spopov/results/folds/folds.csv\"\n",
    "\n",
    "# path to the CSV containing the predicted buildings\n",
    "PRED_CSV = \"/Users/spopov/results/folds/pred_csv{}.csv\"\n",
    "\n",
    "# path to the CSV containing the ground-truth buildings\n",
    "GT_CSV = \"/Users/spopov/results/folds/gt_fold{}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_set = SpaceNet6Dataset({\n",
    "    \"root_directory\": ROOT_DIRECTORY,\n",
    "    \"segmentation_directory\": SEGMENTATION_DIRECTORY,\n",
    "    \"folds_dir\": FOLDS_DIR,\n",
    "    \"num_threads\": 12,\n",
    "    \"edge_width\": 3,\n",
    "    \"contact_width\": 9,\n",
    "    \"orients\": ORIENTS,\n",
    "    \"orients_output\": ORIENTS_OUTPUT\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `prepare` method on the dataset object creates the segmentation masks and the training / validation folds. After this step we can actually ignore the `raw_data_set` object and create new `SpaceNet6DataSet` objects for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# raw_data_set.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from aitlas.models import UNetEfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `aitlas` we have implemented the winning base model of the challenge. More information can be found in this [paper](https://proceedings.mlr.press/v97/tan19a/tan19a.pdf), in Table 2 under **Efficient Net B5**. Using this model requires installation of few packages that are not specified as requirements for `aitlas`, since they are unique to this use case. Refer to the source code of `aitlas.models.unet_efficientnet.py` for information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spopov/Downloads/aitlas/venv/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "model = UNetEfficientNet({\n",
    "    \"net\": \"b5\",\n",
    "    \"stride\": 32,\n",
    "    \"use_cuda\": True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_set = SpaceNet6Dataset({\n",
    "    \"batch_size\": 4,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 8,\n",
    "    \"transforms\": [\n",
    "        \"aitlas.transforms.SpaceNet6Transforms\"\n",
    "    ],\n",
    "    \"orients\": ORIENTS_OUTPUT,\n",
    "    \"pred_folder\": PRED_FOLDER,\n",
    "    \"folds_path\": FOLDS_PATH,\n",
    "    \"root_directory\": ROOT_DIRECTORY,\n",
    "    \"segmentation_directory\": SEGMENTATION_DIRECTORY,\n",
    "    \"edge_weight\": 0.25,\n",
    "    \"contact_weight\": 0.1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_set = SpaceNet6Dataset({\n",
    "    \"batch_size\": 1,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 1,\n",
    "    \"orients\": ORIENTS_OUTPUT,\n",
    "    \"folds_path\": FOLDS_PATH,\n",
    "    \"root_directory\": ROOT_DIRECTORY,\n",
    "    \"start_val_epoch\": 0,\n",
    "    \"pred_csv\": PRED_CSV,\n",
    "    \"gt_csv\": GT_CSV\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we just call `train_and_evaluate_model`. This will train the model for the specified number of epochs, and after the `start_val_epoch` will evaluate its performance in terms of F1 score, where precision and recall would be calculated on a pixel level (precision is the number of pixels that are predicted and are actually buildings out of all predicted as buildings, and recall is the number of pixels that are predicted as buildings out of all pixels that are buildings). The predicted images will be stored in the `PRED_FOLDER` directory, and a CSV file of all buildings will be outputed at `PRED_CSV` in a format required by the SpaceNet6 challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a21405c1e346b28685e18ad6b4ff25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/694 [00:26<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6c670dc96e4760b710ed4c252a77e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6912db31d3c54af087d1885fdb1280fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21db788c89f54e21a844b4d6c96c2a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train_and_evaluate_model(\n",
    "    train_dataset=training_data_set,\n",
    "    epochs=1,\n",
    "    model_directory=\"/Users/spopov/results/model\",\n",
    "    save_epochs=1,\n",
    "    val_dataset=validation_data_set,\n",
    "    run_id=\"1\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}